{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymppJ2OdW0jk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369.0/369.0\r"
     ]
    }
   ],
   "source": [
    "# the OG\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "video_path =r\"D:\\a netfix\\ML b&w colorizer Project\\5614724-hd_720_1280_30fps.mp4\"\n",
    "print(video_path)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "  print('NOT OPENED')\n",
    "proto = r'D:\\a netfix\\ML b&w colorizer Project\\models\\colorization_deploy_v2.prototxt'\n",
    "weights = r'D:\\a netfix\\ML b&w colorizer Project\\models\\colorization_release_v2.caffemodel'\n",
    "pts_in_hull_path = r'D:\\a netfix\\ML b&w colorizer Project\\models\\pts_in_hull.npy'\n",
    "\n",
    "# Load cluster centers\n",
    "pts_in_hull = np.load(pts_in_hull_path)\n",
    "pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1).astype(np.float32)\n",
    "\n",
    "# Load model\n",
    "net = cv2.dnn.readNetFromCaffe(proto, weights)\n",
    "\n",
    "# Populate cluster centers as 1x1 convolution kernel\n",
    "net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull]\n",
    "net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full((1, 313), 2.606, np.float32)]\n",
    "\n",
    "skipping = False\n",
    "\n",
    "# Initialize video output\n",
    "output_size = (\n",
    "    640,\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * 640 / cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    ")\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('%s_output.mp4' % (video_path.split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img = cv2.resize(img, output_size)\n",
    "\n",
    "    pred_bgr = img.copy()\n",
    "    img_ori = img.copy()\n",
    "\n",
    "    # Normalize input\n",
    "    img_ori = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "    img_ori = cv2.cvtColor(img_ori, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    if not skipping:\n",
    "        img_ori = (img_ori / 255.).astype(np.float32)\n",
    "\n",
    "        # Convert RGB to LAB\n",
    "        img_lab = cv2.cvtColor(img_ori, cv2.COLOR_RGB2Lab)\n",
    "        img_l = img_lab[:, :, 0]\n",
    "\n",
    "        input_img = cv2.resize(img_l, (224, 224))\n",
    "        input_img -= 50  # Subtract 50 for mean-centering\n",
    "\n",
    "        # Prediction\n",
    "        net.setInput(cv2.dnn.blobFromImage(input_img))\n",
    "        pred = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
    "\n",
    "        # Resize to original image shape\n",
    "        pred_resize = cv2.resize(pred, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        # Concatenate with original image L\n",
    "        pred_lab = np.concatenate([img_l[:, :, np.newaxis], pred_resize], axis=2)\n",
    "\n",
    "        # Convert LAB to RGB\n",
    "        pred_bgr = cv2.cvtColor(pred_lab, cv2.COLOR_Lab2BGR)\n",
    "        pred_bgr = np.clip(pred_bgr, 0, 1) * 255\n",
    "        pred_bgr = pred_bgr.astype(np.uint8)\n",
    "\n",
    "    # Write the output frame to video\n",
    "    out.write(pred_bgr)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        skipping = not skipping\n",
    "\n",
    "    print('%s/%s' % (cap.get(cv2.CAP_PROP_POS_FRAMES), n_frames), end='\\r')\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"D:\\a netfix\\ML b&w colorizer Project\\models\\colorization_deploy_v2.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m pts_in_hull_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpts_in_hull.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load model and cluster centers\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromCaffe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m pts_in_hull \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(pts_in_hull_path)\u001b[38;5;241m.\u001b[39mtranspose()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m313\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     24\u001b[0m net\u001b[38;5;241m.\u001b[39mgetLayer(net\u001b[38;5;241m.\u001b[39mgetLayerId(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass8_ab\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mblobs \u001b[38;5;241m=\u001b[39m [pts_in_hull]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"D:\\a netfix\\ML b&w colorizer Project\\models\\colorization_deploy_v2.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "FFMPEG_PATH = r\"C:\\ffmpeg\\ffmpeg.exe\"\n",
    "FFPROBE_PATH = r\"C:\\ffmpeg\\ffprobe.exe\"\n",
    "output_dir = r\"D:\\a netfix\\ML b&w colorizer Project\"\n",
    "\n",
    "# Model files\n",
    "proto = os.path.join(output_dir, \"models\", \"colorization_deploy_v2.prototxt\")\n",
    "weights = os.path.join(output_dir, \"models\", \"colorization_release_v2.caffemodel\")\n",
    "pts_in_hull_path = os.path.join(output_dir, \"models\", \"pts_in_hull.npy\")\n",
    "\n",
    "# Load model and cluster centers\n",
    "net = cv2.dnn.readNetFromCaffe(proto, weights)\n",
    "pts_in_hull = np.load(pts_in_hull_path).transpose().reshape(2, 313, 1, 1).astype(np.float32)\n",
    "net.getLayer(net.getLayerId(\"class8_ab\")).blobs = [pts_in_hull]\n",
    "net.getLayer(net.getLayerId(\"conv8_313_rh\")).blobs = [np.full((1, 313), 2.606, np.float32)]\n",
    "\n",
    "# UI widgets\n",
    "file_input = widgets.Text(placeholder='Enter full path to image or video...', layout=widgets.Layout(width='100%'))\n",
    "colorize_btn = widgets.Button(description=\"üé® Colorize\", button_style='success')\n",
    "bw_btn = widgets.Button(description=\"‚ö´ Convert to B&W\", button_style='danger')\n",
    "status_output = widgets.Output()\n",
    "timer_label = widgets.Label(value=\"‚è±Ô∏è Timer: 0.0 seconds\")\n",
    "frame_label = widgets.Label(value=\"üßÆ Frame: 0/0\")\n",
    "\n",
    "def update_timer(start_time, stop_flag):\n",
    "    while not stop_flag[0]:\n",
    "        elapsed = time.time() - start_time[0]\n",
    "        timer_label.value = f\"‚è±Ô∏è Timer: {elapsed:.1f} seconds\"\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def has_audio(video_path):\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            FFPROBE_PATH, \"-v\", \"error\", \"-select_streams\", \"a\", \"-show_entries\",\n",
    "            \"stream=codec_type\", \"-of\", \"csv=p=0\", video_path\n",
    "        ], capture_output=True, text=True)\n",
    "        return \"audio\" in result.stdout\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def preview_media(filepath):\n",
    "    ext = os.path.splitext(filepath)[-1].lower()\n",
    "    if ext in ['.jpg', '.jpeg', '.png']:\n",
    "        display(Image(filename=filepath))\n",
    "    # Video preview intentionally removed\n",
    "\n",
    "def colorize_frame(frame):\n",
    "    frame = cv2.resize(frame, (640, int(frame.shape[0] * 640 / frame.shape[1])))\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    img_input = (gray_rgb / 255.).astype(np.float32)\n",
    "    img_lab = cv2.cvtColor(img_input, cv2.COLOR_RGB2Lab)\n",
    "    img_l = img_lab[:, :, 0]\n",
    "    input_img = cv2.resize(img_l, (224, 224)) - 50\n",
    "    net.setInput(cv2.dnn.blobFromImage(input_img))\n",
    "    pred = net.forward()[0].transpose((1, 2, 0))\n",
    "    pred_resize = cv2.resize(pred, (frame.shape[1], frame.shape[0]))\n",
    "    pred_lab = np.concatenate([img_l[:, :, np.newaxis], pred_resize], axis=2)\n",
    "    pred_bgr = cv2.cvtColor(pred_lab, cv2.COLOR_Lab2BGR)\n",
    "    return np.clip(pred_bgr, 0, 1) * 255\n",
    "\n",
    "def convert_to_bw(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "def process_media(file_path, mode=\"colorize\"):\n",
    "    with status_output:\n",
    "        clear_output()\n",
    "        try:\n",
    "            start, stop = [time.time()], [False]\n",
    "            threading.Thread(target=update_timer, args=(start, stop)).start()\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                raise FileNotFoundError(\"‚ùå File does not exist!\")\n",
    "\n",
    "            ext = os.path.splitext(file_path)[-1].lower()\n",
    "            output_path = os.path.join(output_dir, f\"{mode}_{os.path.basename(file_path)}\")\n",
    "\n",
    "            if ext in ['.jpg', '.jpeg', '.png']:\n",
    "                img = cv2.imread(file_path)\n",
    "                if mode == \"colorize\":\n",
    "                    out_img = colorize_frame(img)\n",
    "                else:\n",
    "                    out_img = convert_to_bw(img)\n",
    "                cv2.imwrite(output_path, out_img.astype(np.uint8))\n",
    "                stop[0] = True\n",
    "                preview_media(output_path)\n",
    "                print(f\"‚úÖ Output saved at: {output_path}\")\n",
    "\n",
    "            elif ext in ['.mp4', '.avi', '.mov', '.mkv']:\n",
    "                cap = cv2.VideoCapture(file_path)\n",
    "                if not cap.isOpened():\n",
    "                    raise ValueError(\"‚ùå Failed to open video\")\n",
    "\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                width = 640\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * width / cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "                temp_video = os.path.join(output_dir, \"temp_no_audio.mp4\")\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                out = cv2.VideoWriter(temp_video, fourcc, fps, (width, height))\n",
    "\n",
    "                frame_idx = 0\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    frame = cv2.resize(frame, (width, height))\n",
    "                    if mode == \"colorize\":\n",
    "                        frame_out = colorize_frame(frame)\n",
    "                    else:\n",
    "                        frame_out = convert_to_bw(frame)\n",
    "                    out.write(frame_out.astype(np.uint8))\n",
    "                    frame_idx += 1\n",
    "                    frame_label.value = f\"üßÆ Frame: {frame_idx}/{total_frames}\"\n",
    "\n",
    "                cap.release()\n",
    "                out.release()\n",
    "\n",
    "                if has_audio(file_path):\n",
    "                    subprocess.run([\n",
    "                        FFMPEG_PATH,\n",
    "                        \"-y\", \"-i\", temp_video,\n",
    "                        \"-i\", file_path,\n",
    "                        \"-c:v\", \"copy\", \"-c:a\", \"aac\",\n",
    "                        \"-map\", \"0:v:0\", \"-map\", \"1:a:0?\",\n",
    "                        output_path\n",
    "                    ])\n",
    "                    os.remove(temp_video)\n",
    "                else:\n",
    "                    shutil.move(temp_video, output_path)\n",
    "\n",
    "                stop[0] = True\n",
    "                # No video preview here\n",
    "                print(f\"‚úÖ Output saved at: {output_path}\")\n",
    "            else:\n",
    "                raise ValueError(\"‚ùå Unsupported file type.\")\n",
    "        except Exception as e:\n",
    "            stop[0] = True\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def handle_colorize(b):\n",
    "    clear_output(wait=True)\n",
    "    display(file_input, colorize_btn, bw_btn, timer_label, frame_label, status_output)\n",
    "    process_media(file_input.value.strip('\"'), mode=\"colorize\")\n",
    "\n",
    "def handle_bw(b):\n",
    "    clear_output(wait=True)\n",
    "    display(file_input, colorize_btn, bw_btn, timer_label, frame_label, status_output)\n",
    "    process_media(file_input.value.strip('\"'), mode=\"bw\")\n",
    "\n",
    "colorize_btn.on_click(handle_colorize)\n",
    "bw_btn.on_click(handle_bw)\n",
    "\n",
    "# Display UI\n",
    "display(file_input, colorize_btn, bw_btn, timer_label, frame_label, status_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled38.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
